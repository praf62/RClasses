, xlab = "Probability", ylab = "hasKnowledgment"
, main = "hasKnowledgment prior distribution")#plot the prior
bn.fit.barchart(dfit$correctAnswer_Q01
, xlab = "hasKnowledgment", ylab = "correctAnswer_Q01"
, main = "P(correctAnswer_Q01|hasKnowledgment)")#plot the likelihood
#COMPUTING THE POSTERIOR/MARGINAL DISTRIBUTIONS
cpquery(fitted = dfit,
event = (hasKnowledgment=="YES"),
evidence = (correctAnswer_Q01=="YES"),
method = "ls"#"lw" leads to an error
, n = 100000)#the sample size of the method
#COMPUTING THE POSTERIOR/MARGINAL DISTRIBUTIONS
cpquery(fitted = dfit,
event = (hasKnowledgment=="YES"),
evidence = (correctAnswer_Q01=="YES"),
method = "ls"#"lw" leads to an error
, n = 1000000)#the sample size of the method
#COMPUTING THE POSTERIOR/MARGINAL DISTRIBUTIONS
cpquery(fitted = dfit,
event = (hasKnowledgment=="YES"),
evidence = (correctAnswer_Q01=="YES"),
method = "ls"#"lw" leads to an error
, n = 10000000)#the sample size of the method
#INVOLVING A SECOND QUESTION, MORE DIFFICULT TO ANSWER...
#LIKELIHOODS
cpt_correctAnswer_Q02 = matrix(c(.9, .25,#mesmo com conhecimento, erra-se mais
.1, .75)
, ncol = 2, byrow = TRUE,
dimnames = list(correctAnswer_Q02 = c("YES", "NO"),
hasKnowledgment = c("YES", "NO")))
#THE BNN
net2 =
model2network("[hasKnowledgment][correctAnswer_Q01|hasKnowledgment][correctAnswer_Q02|hasKnowledgment]")
dfit2 = custom.fit(net2, dist = list(hasKnowledgment = cpt_hasKnowledgment
, correctAnswer_Q01 = cpt_correctAnswer_Q01
, correctAnswer_Q02 = cpt_correctAnswer_Q02))
#BBN (for qualitative analysis)
graphviz.plot(dfit2, layout = "dot", #LAYOUT=dot, neato, twopi, circo, and fdp
shape = "rectangle", #circle, ellipse or rectangle
main = "Rede Bayesiana #2")#supõe-se a priori que as questões são independentes
#BBN (for qualitative analysis)
graphviz.plot(dfit2, layout = "dot", #LAYOUT=dot, neato, twopi, circo, and fdp
shape = "rectangle", #circle, ellipse or rectangle
main = "Rede Bayesiana #2")#supõe-se a priori que as questões são independentes
bn.fit.dotplot(fitted = dfit2$hasKnowledgment
, xlab = "Probability", ylab = "hasKnowledgment"
, main = "hasKnowledgment prior distribution")#plot the prior
bn.fit.barchart(dfit2$correctAnswer_Q01
, xlab = "hasKnowledgment", ylab = "correctAnswer_Q01"
, main = "P(correctAnswer_Q01|hasKnowledgment)")#plot the likelihood
bn.fit.barchart(dfit2$correctAnswer_Q02
, xlab = "hasKnowledgment", ylab = "correctAnswer_Q02"
, main = "P(correctAnswer_Q02|hasKnowledgment)")#plot the likelihood
#COMPUTING THE POSTERIOR/MARGINAL DISTRIBUTIONS
cpquery(fitted = dfit2,
event = (hasKnowledgment=="YES"),
evidence = ((correctAnswer_Q01=="YES") & (correctAnswer_Q02=="YES")),
method = "ls"#"lw" leads to an error
, n = 100000)#the sample size of the method
factorial(10)
10A5 = factorial(10)/factorial(10-5)
aranjo_10A5 = factorial(10)/factorial(10-5)
aranjo_10A5
choose(10,5)
500*52560
#Content available in page http://www.openreliability.org/faulttree-users-tutorial/start-faulttree-on-r/
#PACKAGE INSTALLATION AND LOADING
#install.packages("FaultTree", repos="http://R-Forge.R-project.org")
library(FaultTree)
install.packages("FaultTree", repos="http://R-Forge.R-project.org")
#Content available in page http://www.openreliability.org/faulttree-users-tutorial/start-faulttree-on-r/
#PACKAGE INSTALLATION AND LOADING
#install.packages("FaultTree", repos="http://R-Forge.R-project.org")
library(FaultTree)
#FAULT TREE DESIGN (QUALITATIVE ANALYSIS) FOR AIRPLANE FALL
tree_quedaAviao = ftree.make(type="and", name="Queda de Aviao")#Nó 01
tree_quedaAviao = addLogic(tree_quedaAviao, at=1, type="or", name="Erro Humano")#Nó 02 (at=1 implica que esse nó será filho do Nó 1)
tree_quedaAviao = addLogic(tree_quedaAviao, at=1, type="or", name="Falha Tecnologica")#Nó 03
#X: tempo até a fadiga de uma pessoa (em horas de vôo)
#X ~ Exponencial (rate = .001 incidência/hora)
#Para aquele dia, o plano de trabalho envolverá 8 horas de vôo
pFadiga = pexp(q=8, rate = .001)#P(X<8h)
#Y: nº, dentre 2 pilotos (o copioto tb), que apresentam sinal de fadiga em 8h
#Y ~ Binomial(n=2, p=pFadiga)
#P(Y=2)
p2Fadiga = dbinom(x=2, size = 2, prob = pFadiga)
tree_quedaAviao = addProbability(tree_quedaAviao, at=2, prob=p2Fadiga, name="Fadiga", name2="no trabalho")
tree_quedaAviao = addProbability(tree_quedaAviao, at=2, prob=.1, name="Inexperiencia", name2="")
tree_quedaAviao = addProbability(tree_quedaAviao, at=2, prob=.05, name="Lapso", name2="de memoria")
tree_quedaAviao = addProbability(tree_quedaAviao, at=3, prob=.05, name="Sistema", name2="mecanico")
tree_quedaAviao = addProbability(tree_quedaAviao, at=3, prob=.09, name="Sistema", name2="eletrico")
tree_quedaAviao = addProbability(tree_quedaAviao, at=3, prob=.01, name="Sistema", name2="eletronico")
tree_quedaAviao = addProbability(tree_quedaAviao, at=3, prob=.005, name="Sistema", name2="software")
View(tree_quedaAviao)
tree_nodesCaracteristics = ftree2html(tree_quedaAviao, write_file=TRUE)
browseURL("tree_quedaAviao.html")
#PROBABILITY OCCURRENCE CALCULATIONS
prob_quedaAviao=ftree.calc(tree_quedaAviao, use.bdd = TRUE)
View(prob_quedaAviao)
#View(prob_quedaAviao)
# ftree2html(prob_quedaAviao, write_file=TRUE)
browseURL("prob_quedaAviao.html")
#CUT SETS COMPUTATION
cs_quedaAviao<-cutsets(tree_quedaAviao)[[2]]
cs_quedaAviao
#cs_tags2<-apply(cs_quedaAviao[[2]], c(1,2),function(x) tree_quedaAviao$Tag[which(tree_quedaAviao$ID==x)])
nCs = nrow(cs_quedaAviao)
cutSets = NULL
library(doParallel)
#library(doParallel)
for (i in 1:nCs) {#i=1
cs_i_tags = cs_quedaAviao[i,]
cs_i_length =length(cs_tags_i)
cs_i_indexes =
foreach(j = 1:cs_i_length, .combine = c) %do% {
cs_i_tag_j = cs_i_tags[j]
index_ij = which(tree_quedaAviao$Tag==cs_i_tag_j)
return(index_ij)
}
cs_i = paste(paste("[", tree_quedaAviao$Name[cs_i_indexes], "_", tree_quedaAviao$Name2[cs_i_indexes], "]", sep=""), collapse ="^")
cs_i = gsub(pattern = " ", replacement = "_", x = cs_i)
cs_prob = prod(tree_quedaAviao$PBF[cs_i_indexes])#Os eventos do corte mínimo são supostos independentes entre si
df_i  = cbind( CUT = cs_i, PROBABILITY = cs_prob)
cutSets = rbind(cutSets, df_i)
}
cutSets = NULL
#library(doParallel)
for (i in 1:nCs) {#i=1
cs_i_tags = cs_quedaAviao[i,]
cs_i_length =length(cs_i_tags)
cs_i_indexes =
foreach(j = 1:cs_i_length, .combine = c) %do% {
cs_i_tag_j = cs_i_tags[j]
index_ij = which(tree_quedaAviao$Tag==cs_i_tag_j)
return(index_ij)
}
cs_i = paste(paste("[", tree_quedaAviao$Name[cs_i_indexes], "_", tree_quedaAviao$Name2[cs_i_indexes], "]", sep=""), collapse ="^")
cs_i = gsub(pattern = " ", replacement = "_", x = cs_i)
cs_prob = prod(tree_quedaAviao$PBF[cs_i_indexes])#Os eventos do corte mínimo são supostos independentes entre si
df_i  = cbind( CUT = cs_i, PROBABILITY = cs_prob)
cutSets = rbind(cutSets, df_i)
}
install.packages("doParallel")
library(doParallel)
for (i in 1:nCs) {#i=1
cs_i_tags = cs_quedaAviao[i,]
cs_i_length =length(cs_i_tags)
cs_i_indexes =
foreach(j = 1:cs_i_length, .combine = c) %do% {
cs_i_tag_j = cs_i_tags[j]
index_ij = which(tree_quedaAviao$Tag==cs_i_tag_j)
return(index_ij)
}
cs_i = paste(paste("[", tree_quedaAviao$Name[cs_i_indexes], "_", tree_quedaAviao$Name2[cs_i_indexes], "]", sep=""), collapse ="^")
cs_i = gsub(pattern = " ", replacement = "_", x = cs_i)
cs_prob = prod(tree_quedaAviao$PBF[cs_i_indexes])#Os eventos do corte mínimo são supostos independentes entre si
df_i  = cbind( CUT = cs_i, PROBABILITY = cs_prob)
cutSets = rbind(cutSets, df_i)
}
View(cutSets)
#VARIÁVEIS ALEATÓRIAS CONTÍNUAS
#Uniforme Contínua
x = 1:6
fx = dunif(x = x, min = min(x), max = max(x))
plot(x, fx, type='l')
#Exponencial
#x: Tempo até a falha de um avião (em anos)
lambda = .001#taxa de ocorrências de falhas por ano (unidade de medida)
x = 0:1000
fx = dexp(x = x, rate = lambda)
plot(x, fx, type='l')
Rx = pexp(q = 10, rate = lambda, lower.tail = FALSE)#P(X>x)
plot(x, Rx, type='l')
Rx
#Normal
#X: estatura de uma pessoa qualquer, do grupo de interesse (em metros)
m = 1.68 #(estatura em metros)
#Content available in page http://www.openreliability.org/faulttree-users-tutorial/start-faulttree-on-r/
#PACKAGE INSTALLATION AND LOADING
#install.packages("FaultTree", repos="http://R-Forge.R-project.org")
library(FaultTree)
#FAULT TREE DESIGN (QUALITATIVE ANALYSIS) FOR AIRPLANE FALL
tree_quedaAviao = ftree.make(type="and", name="Queda de Aviao")#Nó 01
tree_quedaAviao = addLogic(tree_quedaAviao, at=1, type="or", name="Erro Humano")#Nó 02 (at=1 implica que esse nó será filho do Nó 1)
tree_quedaAviao = addLogic(tree_quedaAviao, at=1, type="or", name="Falha Tecnologica")#Nó 03
#X: tempo até a fadiga de uma pessoa (em horas de vôo)
#X ~ Exponencial (rate = .001 incidência/hora)
#Para aquele dia, o plano de trabalho envolverá 8 horas de vôo
pFadiga = pexp(q=8, rate = .001)#P(X<8h)
#Y: nº, dentre 2 pilotos (o copioto tb), que apresentam sinal de fadiga em 8h
#Y ~ Binomial(n=2, p=pFadiga)
#P(Y=2)
p2Fadiga = dbinom(x=2, size = 2, prob = pFadiga)
tree_quedaAviao = addProbability(tree_quedaAviao, at=2, prob=p2Fadiga, name="Fadiga", name2="no trabalho")
tree_quedaAviao = addProbability(tree_quedaAviao, at=2, prob=.1, name="Inexperiencia", name2="")
tree_quedaAviao = addProbability(tree_quedaAviao, at=2, prob=.05, name="Lapso", name2="de memoria")
tree_quedaAviao = addProbability(tree_quedaAviao, at=3, prob=.05, name="Sistema", name2="mecanico")
tree_quedaAviao = addProbability(tree_quedaAviao, at=3, prob=.09, name="Sistema", name2="eletrico")
tree_quedaAviao = addProbability(tree_quedaAviao, at=3, prob=.01, name="Sistema", name2="eletronico")
tree_quedaAviao = addProbability(tree_quedaAviao, at=3, prob=.005, name="Sistema", name2="software")
tree_nodesCaracteristics = ftree2html(tree_quedaAviao, write_file=TRUE)
browseURL("tree_quedaAviao.html")
#para ter controle sobre os números pseudo-aleatórios gerados...
set.seed(1)#para controlar a sequência gerada de números pseudo-aleatórios
#Exemplo: Conjunto de dados de manutenção
#Ler o conjunto
BD01 <- read.csv(file = "./data/BD01.csv", dec = ",", encoding="UTF-8", sep=";", quote="")
#visualizar o conjunto
View(BD01)
#amostragem aleatoria simples - AASimples
getSimpleRandomSample = function(dataFrame, sampleSize){
N = nrow(dataFrame) #tamanho da população
n = sampleSize # tamanho da amostra
#amostra aleatória de índices
sampleIndexes = sample(x = 1:N, size = n, replace = FALSE)
#separando a amostra aleatória correspondente aos índices sorteados
sampleData = dataFrame[sampleIndexes, ]
return(sampleData)
}
#Descritiva (script01)
descritiva = function(data){
#para carregar funções criadas por mim
debugSource('./R/classicBoxPlot.R', encoding = 'UTF-8')
debugSource('./R/distribFreq.R', encoding = 'UTF-8')
debugSource('./R/iqv_function.R', encoding = 'UTF-8')
debugSource('./R/mode_function.R', encoding = 'UTF-8')
distFreq(x = data$Fornecedor)
ourMode(sample = data$Fornecedor, xlab = "Fornecedor", toPrint = TRUE)
ourMode(sample = data$TempoFalha, xlab = "Tempo até a falha", toPrint = TRUE, minimalAmplitudeRatioForGrouping = .2)
ourMode(sample = data$nReincidenciaFalhas, xlab = "Nº de reincidências de falhas", toPrint = TRUE, minimalAmplitudeRatioForGrouping = .2)
}
aaSimples_data = getSimpleRandomSample(dataFrame = BD01, sampleSize = 5)
View(aaSimples_data)
descritiva(aaSimples_data)
#Descritiva (script01)
descritiva = function(data){
#para carregar funções criadas por mim
debugSource('./R/classicBoxPlot.R', encoding = 'UTF-8')
debugSource('./R/distribFreq.R', encoding = 'UTF-8')
debugSource('./R/iqv_function.R', encoding = 'UTF-8')
debugSource('./R/mode_function.R', encoding = 'UTF-8')
distFreq(x = data$Fornecedor)
ourMode(sample = data$Fornecedor, xlab = "Fornecedor", toPrint = TRUE)
ourMode(sample = data$TempoFalha, xlab = "Tempo até a falha", toPrint = TRUE)#, minimalAmplitudeRatioForGrouping = .2)
ourMode(sample = data$nReincidenciaFalhas, xlab = "Nº de reincidências de falhas", toPrint = TRUE, minimalAmplitudeRatioForGrouping = .2)
}
descritiva(aaSimples_data)
1:10
#para ter controle sobre os números pseudo-aleatórios gerados...
set.seed(1)#para controlar a sequência gerada de números pseudo-aleatórios
#amostragem aleatoria simples - AASimples
getSimpleRandomSample = function(dataFrame, sampleSize){
N = nrow(dataFrame) #tamanho da população
n = sampleSize # tamanho da amostra
#amostra aleatória de índices
sampleIndexes = sample(x = 1:N, size = n, replace = FALSE)
#separando a amostra aleatória correspondente aos índices sorteados
sampleData = dataFrame[sampleIndexes, ]
return(sampleData)
}
#Exemplo: Conjunto de dados de manutenção
#Ler o conjunto
BD01 <- read.csv(file = "./data/BD01.csv", dec = ",", encoding="UTF-8", sep=";", quote="")
#visualizar o conjunto
View(BD01)
aaSimples_data = getSimpleRandomSample(dataFrame = BD01, sampleSize = 5)
View(aaSimples_data)
#amostragem aleatoria sistemática - AASistemática
getMapingBasedSimpleRandomSample = function(dataFrame, sampleSize){
N = nrow(dataFrame) #tamanho da população
n = sampleSize # tamanho da amostra
ti = 1; tf = N # mínimo e máximo do intervalo de chaves
d = round((tf - ti + 1)/n) # distância entre índices subsequentes
#primeiro índice sorteado aleatoriamente (como na AASimples)
i0 = sample(x = ti:tf, size = 1, replace = FALSE)
#sorteando índices a partir de i0, distanciados por d
sampleIndexes = i0 + seq(from=0, by = d, length.out = n)
#contornando o problema de índice maior que o máximo possível
sampleIndexes[sampleIndexes>tf] =
sampleIndexes[sampleIndexes>tf] - tf + ti - 1
#separando a amostra aleatória correspondente aos índices sorteados
sampleData = dataFrame[sampleIndexes, ]
return(sampleData)
}
aaSistematica = getMapingBasedSimpleRandomSample(dataFrame = BD01, sampleSize = 5)
View(aaSistematica)
#amostragem aleatoria estratificada proporcional - AAEstrProp
getProportionalStratifiedRandomSample = function(dataFrame
, sampleSize
, stratumVariable){
#distribuição da variável de estrato na população
n = sampleSize
probDist = prop.table(table(dataFrame[[stratumVariable]])); #View(probDist)
ns = round(n*probDist); #View(ns)
stratums = names(probDist)
nStratums = length(stratums)
sampleData = NULL
for(i in 1:nStratums){
stratum_i = stratums[i]
dataFrame_i = dataFrame[dataFrame[[stratumVariable]] == stratum_i, ]#View(dataFrame_i, title = stratum_i)
N_i = nrow(dataFrame_i) #tamanho da iª população
n_i = as.integer(ns[i]) # tamanho da iª amostra
sampleData_i = getSimpleRandomSample(dataFrame = dataFrame_i, sampleSize = n_i)#View(sampleData_i, title = paste("amostra_", stratum_i) )
sampleData = rbind(sampleData, sampleData_i)
}
return(sampleData)
}
debugSource("G:/Meu Drive/UFCA/Ensino/CRAN R_aulas/RClasses/R/script02_amostragem.R", encoding = 'UTF-8', echo=TRUE)
debugSource("G:/Meu Drive/UFCA/Ensino/CRAN R_aulas/RClasses/R/script02_amostragem.R", encoding = 'UTF-8', echo=TRUE)
View(sampleData_i)
View(dataFrame_i)
View(sampleData_i)
View(sampleData_i)
View(sampleData)
#Exemplo: Mapeamento
bounds = list(lat = list(min = -10, max = -1)
, long = list(min = 15, max = 20)
, tempo = list(min = 7, max = 22))
#amostragem aleatória simples por mapeamento - AASM
getMapingSimpleRandomSample = function(bounds, sampleSize){
dimensions = names(bounds)
nDimensions = length(dimensions)
# N = nrow(dataFrame) #tamanho da população
n = sampleSize # tamanho da amostra
#amostra aleatória de coordenadas
sampleCoordinates = list()
for(i in 1:nDimensions){#i=1
dim_i = dimensions[i]
#amostra aleatória simples para a dimensão dim_i
rs_i = runif(n = n, min = bounds[[i]][["min"]], max = bounds[[i]][["max"]])
sampleCoordinates[[dim_i]] = rs_i
}
sampleCoordinates = as.data.frame(sampleCoordinates)#View(sampleCoordinates)
return(sampleCoordinates)
}
aasm_data = getMapingSimpleRandomSample(bounds = bounds, sampleSize = 5)
debugSource("G:/Meu Drive/UFCA/Ensino/CRAN R_aulas/RClasses/R/script02_amostragem.R", encoding = 'UTF-8', echo=TRUE)
source('./R/iqv_function.R', encoding = 'UTF-8')
# ler o conjunto de dados
BD01 = read.csv(file = "G:/Meu Drive/UFCA/Ensino/CRAN R_aulas/RClasses/data/BD01.csv", dec = ".", encoding="UTF-8", sep=";", quote="")
#medidas de dispersão
df_fornecedor  = table(BD01$Fornecedor)
?table
trash = table(c(6, 11, 2, 1)); iqv(freq = trash, varName = "trash")
trash = table(c(rep(10, 6), rep(9, 11), rep(8, 2), rep(7, 1))); iqv(freq = trash, varName = "trash")
trash_data = (c(rep(10, 6), rep(9, 11), rep(8, 2), rep(7, 1)));
trash_data = (c(rep(10, 6), rep(9, 11), rep(8, 2), rep(7, 1)));
trash_tb = table(trash_data)
iqv(freq = trash_tb, varName = "trash")
mean(trash_data)
##trash
# trash_data = (c(rep(10, 6), rep(9, 11), rep(8, 2), rep(7, 1)));
trash_data = (c(rep("Sim", 13), rep("Não", 3), rep("Talvez", 4)));
trash_tb = table(trash_data)
iqv(freq = trash_tb, varName = "trash")
# ler o conjunto de dados
BD01 = read.csv(file = "G:/Meu Drive/UFCA/Ensino/CRAN R_aulas/RClasses/data/BD01.csv", dec = ".", encoding="UTF-8", sep=";", quote="")
#para visualizar o conjunto
View(BD01)
source("G:/Meu Drive/UFCA/Ensino/CRAN R_aulas/RClasses/R/TeoremaDoLimiteCentral.R", encoding = 'UTF-8', echo=TRUE)
#2. (Bussab & Morettin) Estuda-se se a distribuição de Poisson (λ=3.87)
# adere ao conjunto de dados sintetizados na tabela
# abaixo, sobre o nº de substâncias radioativas desintegradas em uma
# amostra de 2608 unidades de tempo de 7.5 segundos.
#Nº de desintegrações 0 1 2 3 4 5 6 7 8 9 ≥10
# Frequência observada 57 203 383 525 532 408 273 139 45 27 16
o = c(57, 203, 383, 525, 532, 408, 273, 139, 45, 27, 16)
p0 = dpois(x = 0:9, lambda = 3.87)
p0
p0 = c(p0, 1-sum(p0))
n = sum(o)#tamanho da amostra
e = n*p0#frequencias esperadas
e
which(e<=5)
plot(o, type="h")
lines(e, col="blue", type="l")
chisq.adherence.test = function(observed, expected){
residuals = (observed - expected)/sqrt(expected)#the Pearson residuals, (observed - expected) / sqrt(expected).
statistic = sum(residuals^2)#Estatística Qui-Quadrado
df = length(observed)-1#nº de graus de liberdade
p.value = pchisq(q = statistic, df=df, lower.tail = FALSE)
ret = list(statistic = statistic, df = df
, p.value = p.value, observed = observed
, expected = expected, residuals = residuals)
return(ret)
}
cat = chisq.adherence.test(observed = o, expected = e)
cat$p.value
#3. Questiona-se se os dados a seguir são normalmente distribuídos
amostra=c(7.53, 7.67, 12.78, 10.82, 10.74, 10.64, 7.75, 7.61, 10.83, 8.49)
x_bar = mean(amostra)
chisq.adherence.test = function(observed, expected){
residuals = (observed - expected)/sqrt(expected)#the Pearson residuals, (observed - expected) / sqrt(expected).
statistic = sum(residuals^2)#Estatística Qui-Quadrado
df = length(observed)-1#nº de graus de liberdade
p.value = pchisq(q = statistic, df=df, lower.tail = FALSE)
ret = list(statistic = statistic, df = df
, p.value = p.value, observed = observed
, expected = expected, residuals = residuals)
return(ret)
}
#3. Questiona-se se os dados a seguir são normalmente distribuídos
amostra=c(7.53, 7.67, 12.78, 10.82, 10.74, 10.64, 7.75, 7.61, 10.83, 8.49)
x_bar = mean(amostra)
s = sd(amostra)
n = length(amostra)
hist(amostra, freq = FALSE)
normDensity = function(x){
dnorm(x, mean = x_bar, sd = s)
}
curve(expr = normDensity(x), from =  min(amostra)
, to = max(amostra), col="blue", add=TRUE)
?pnorm
kst = ks.test(x = amostra, "pnorm", mean=x_bar, sd = s)#Teste de Kolmogorov-Smirnov
kst$p.value
sht = shapiro.test(x = amostra)#Teste de normalidade (adequado para pequenas amostras)
sht$p.value
## Dados
x <- c(3,5,10,10,20,20,20,30,40,50,60,70,70,80,100,100,100,
120,120,140,150,180,180,200,200, 1000, 2000)
y <- c(1.5,2.0,6.0,7.0,10.0,12.0,15.0,8.0,10.0,20.0,20.0,25.0,
30.0,25.0,40.0,35.0,40.0,30.0,40.0,40.0,50.0,40.0,50.0,
60.0,50.0, 173, 293)
data0 = cbind(consumo = y, renda = x); View(data0)
##### Análise de correlação linear entre as variáveis ########
## Gráfico: Diagrama de Dispersão
plot(x,y, xlab="Renda Familiar (U.M.)", ylab="Gasto com Alimentação (U.M.)",
pch=16, las=1,
main="Gasto com alimentação em função da renda\n familiar em U.M.")
################## Ajuste do MRLS
## Y = a + b*x
model <- lm(y ~ x); model
## Ex.2: Precipitação semanal de chuva
#s_t - estação do ano na semana t - Verão (0) e outono (1)
# x_t - precipitação observada na semana t (em milímetros  - mm)
s_t = c(0, 0, 0, 0, 0, 1, 1, 1, 1, 1)#Estação do ano
x_t = c(2.9, 3.8, 10.5, 17, 16.7, 19, 23.7, 24.9, 24.2, 23.3)#precipitacao
data = cbind(s_t, x_t); View(data)
#Construa um modelo linear que permita estimar a precipitação
# na semana t (x_t) a partir da precipitação observada na
# semana anterior (x_{t-1}) e da estação do ano (s_t)
size = nrow(data)
#x_t = x_t[1:size]
#s_t = s_t[1:size]
x_t_1 = c(NA, x_t[1:(size-1)])
data2 = cbind(x_t, x_t_1, s_t); View(data2)
pairs(data2)
model2 = lm(x_t ~ x_t_1 + s_t); model2
res = resid(model)  ## Os resíduos do modelo MRLS
res
##### Normalidade dos resíduos
Norm_test <-function(x){
require(nortest)
t1 <- ks.test(x, "pnorm", mean=mean(x), sd=sd(x)) # KS
t2 <- lillie.test(x)                     # Lilliefors
t3 <- shapiro.test(x)                    # Shapiro-Wilk
# t4 <- ad.test(x)                         # Anderson-Darling
testes <- c(t1$method, t2$method, t3$method)#, t4$method)
valorp <- c(t1$p.value, t2$p.value, t3$p.value)#, t4$p.value)
resultados <- cbind(valorp)
rownames(resultados) <- testes
print(resultados, digits = 4)
}
## Obs.: shapiro.test sugere-nos preferência em relação ao
##       ks.test para amostras de pequenas (n < 30)
Norm_test(res)
##### Verificar a homoscedasticidade
## O teste Breusch-Pagan
# H0: há a homoscedasticidade (a variância do erro
# permanece constante ao longo de valores de Y?)
# H1: não há homoscedasticidade
library(lmtest)
bptest(model)
?bptest
plot(py, z, ylim=c(-2.1,2.1), pch=16, ylab="Resíduos padronizados",
xlab="Gastos com alimentação preditos",
main="Gráficos para análise dos resíduos padronizados")
## Análise gráfica: resíduos padronizados x valores ajustados (ou preditivos)
#  Este gráfico deve apresentar pontos dispostos aleatoriamente
#  sem nenhum padrão definido
z = rstandard(model)#retorna os resíduos padronizados ((x - mean)/sd)
py <- predict(model)
plot(py, z, ylim=c(-2.1,2.1), pch=16, ylab="Resíduos padronizados",
xlab="Gastos com alimentação preditos",
main="Gráficos para análise dos resíduos padronizados")
distFrequencia =
matrix(data =c(  50, 3, 2#original table
, 900, 27, 18)
# matrix(data =c(  5, 3, 2
#                  , 945, 27, 18)
, nrow = 2, ncol = 3, byrow = TRUE
, dimnames =
list(c("Abortou", "Não abortou")
, c("0 mg de Y", "100 mg de Y", "500 mg de Y")))
View(distFrequencia)
ct = chisq.test(x=distFrequencia)#Teste de associação Qui-Quadrado de Pearson
#PACKAGES FOR CORRESPONDENCE ANALYSIS...
# install.packages("ca")
library(ca)
ca(distFrequencia)
distFrequencia =
matrix(data =c(  50, 3, 2#original table
, 900, 27, 18)
# matrix(data =c(  5, 3, 2
#                  , 945, 27, 18)
, nrow = 2, ncol = 3, byrow = TRUE
, dimnames =
list(c("Abortou", "Não abortou")
, c("0 mg de Y", "100 mg de Y", "500 mg de Y")))
ca(distFrequencia)
distFrequencia
?ca
